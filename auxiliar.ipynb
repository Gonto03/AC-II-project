{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and resampling an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_wav_dir_=\"../UrbanSound8K/audio/fold1/\"\n",
    "files = librosa.util.find_files(_wav_dir_)\n",
    "f = files[0]\n",
    "signal, rate = librosa.load(f, sr=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "signal_time = 4    # each signal will have 4 seconds of duration\n",
    "target_rate = 1000    # resampling frequence\n",
    "new_signal = librosa.resample(signal, orig_sr=rate, target_sr=target_rate)\n",
    "len(new_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reflective_padding(signal, target_duration):\n",
    "    current_duration = len(signal)\n",
    "    \n",
    "    # Calculate the required padding on each side\n",
    "    padding_needed = target_duration - current_duration\n",
    "    left_padding = padding_needed // 2\n",
    "    right_padding = padding_needed - left_padding\n",
    "    \n",
    "    # Reflective padding on both sides\n",
    "    padded_signal = np.pad(signal, (left_padding, right_padding), 'reflect')\n",
    "    \n",
    "    return padded_signal\n",
    "\n",
    "# Example usage:\n",
    "# Assuming 'original_signal' is your input signal and 'target_duration' is 4 seconds\n",
    "original_signal = np.array([1, 2, 3, 4, 3, 2, 1])  # Replace this with your actual signal\n",
    "target_duration = 10\n",
    "\n",
    "padded_signal = reflective_padding(original_signal, target_duration)\n",
    "\n",
    "print(\"Original Signal:\", original_signal)\n",
    "print(\"Padded Signal:\", padded_signal)\n",
    "print(\"Padded Signal Duration:\", len(padded_signal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting files names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_wav_dir_=\"../UrbanSound8K/audio/fold10/\"\n",
    "files = librosa.util.find_files(_wav_dir_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in files:\n",
    "    print(str(f)[83:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting a file's label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = \"../UrbanSound8K/metadata/UrbanSound8K.csv\"\n",
    "metadata_df = pd.read_csv(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vari = metadata_df[str(files[0])[82:]==metadata_df['slice_file_name']]['class']\n",
    "print(vari)\n",
    "arr = [vari]\n",
    "print(arr[0] == 'dog_bark')\n",
    "print(arr[0].values[0])\n",
    "print(type(arr[0].values[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
