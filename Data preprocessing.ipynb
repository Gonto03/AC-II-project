{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dde8cb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c19e71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dog_bark' 'children_playing' 'car_horn' 'air_conditioner' 'street_music'\n",
      " 'gun_shot' 'siren' 'engine_idling' 'jackhammer' 'drilling']\n"
     ]
    }
   ],
   "source": [
    "metadata = \"../UrbanSound8K/metadata/UrbanSound8K.csv\"\n",
    "df = pd.read_csv(metadata)\n",
    "\n",
    "labels = df['class'].unique()    # obtaining the class labels\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and resampling an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00332608",
   "metadata": {},
   "outputs": [],
   "source": [
    "_wav_dir_=\"../UrbanSound8K/audio/fold1/\"\n",
    "files = librosa.util.find_files(_wav_dir_)\n",
    "f = files[0]\n",
    "signal, rate = librosa.load(f, sr=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1996c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_time = 4    # each signal will have 4 seconds of duration\n",
    "target_rate = 1000    # resampling frequence\n",
    "new_signal = librosa.resample(signal, orig_sr=rate, target_sr=target_rate)\n",
    "len(new_signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflective padding: our alternative to zero padding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reflective padding:\n",
    "\n",
    "    Reflecting the signal at its boundaries instead of zero padding can help preserve the continuity of the signal, preventing alterations of the signal's characteristics, something that might occur with zero padding.\n",
    "    It can also help reducing artifacts at the edges of the signal and providing a smooth transition from the original signal to the padded region.\n",
    "    We believe this approach is effective with sound data, due to its symmetric nature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reflective_padding(signal, target_duration, target_rate):\n",
    "    target_duration = target_duration*target_rate\n",
    "    current_duration = len(signal)\n",
    "    \n",
    "    # Calculate the required padding on each side\n",
    "    padding_needed = target_duration - current_duration\n",
    "    left_padding = padding_needed // 2\n",
    "    right_padding = padding_needed - left_padding\n",
    "    \n",
    "    # Reflective padding on both sides\n",
    "    padded_signal = np.pad(signal, (left_padding, right_padding), 'reflect')\n",
    "    \n",
    "    return padded_signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and resampling all the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_time = 4    # each signal will have 4 seconds of duration\n",
    "target_rate = 1000    # resampling frequence\n",
    "\n",
    "# MFCC parameters\n",
    "n_mfcc=40\n",
    "hop_length=round(target_rate*0.0125)\n",
    "win_length=round(target_rate*0.023)\n",
    "n_fft=2**14\n",
    "mfcc_time_size = 4*target_rate//hop_length+1\n",
    "\n",
    "dataset=np.zeros(shape=[len(files),4*target_rate])\n",
    "dataset_mfcc=np.zeros(shape=[len(files),n_mfcc,mfcc_time_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtaining all the resampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 873 is out of bounds for axis 0 with size 873",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\gapmd\\workspace\\GitHub projects\\AC II - project\\AC II - project (git)\\Data preprocessing.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gapmd/workspace/GitHub%20projects/AC%20II%20-%20project/AC%20II%20-%20project%20%28git%29/Data%20preprocessing.ipynb#X15sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(new_signal)\u001b[39m<\u001b[39m\u001b[39m4\u001b[39m\u001b[39m*\u001b[39mtarget_rate:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gapmd/workspace/GitHub%20projects/AC%20II%20-%20project/AC%20II%20-%20project%20%28git%29/Data%20preprocessing.ipynb#X15sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     new_signal \u001b[39m=\u001b[39m reflective_padding(new_signal, \u001b[39m4\u001b[39m, target_rate)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/gapmd/workspace/GitHub%20projects/AC%20II%20-%20project/AC%20II%20-%20project%20%28git%29/Data%20preprocessing.ipynb#X15sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m dataset[idx] \u001b[39m=\u001b[39m new_signal\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gapmd/workspace/GitHub%20projects/AC%20II%20-%20project/AC%20II%20-%20project%20%28git%29/Data%20preprocessing.ipynb#X15sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m sig_mfcc \u001b[39m=\u001b[39mlibrosa\u001b[39m.\u001b[39mfeature\u001b[39m.\u001b[39mmfcc(y\u001b[39m=\u001b[39mnew_signal,sr\u001b[39m=\u001b[39mtarget_rate,n_fft\u001b[39m=\u001b[39mn_fft,hop_length\u001b[39m=\u001b[39mhop_length,win_length\u001b[39m=\u001b[39mwin_length,n_mfcc\u001b[39m=\u001b[39mn_mfcc)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gapmd/workspace/GitHub%20projects/AC%20II%20-%20project/AC%20II%20-%20project%20%28git%29/Data%20preprocessing.ipynb#X15sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m dataset_mfcc[idx] \u001b[39m=\u001b[39m sig_mfcc\n",
      "\u001b[1;31mIndexError\u001b[0m: index 873 is out of bounds for axis 0 with size 873"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "for i in range(1,11):\n",
    "    _wav_dir_=\"../UrbanSound8K/audio/fold\" + str(i) + '/'\n",
    "    files = librosa.util.find_files(_wav_dir_)\n",
    "    for f in files:\n",
    "        signal, rate = librosa.load(f, sr=None)\n",
    "        new_signal = librosa.resample(signal, orig_sr=rate, target_sr=target_rate)\n",
    "        if len(new_signal)<4*target_rate:\n",
    "            new_signal = reflective_padding(new_signal, 4, target_rate)\n",
    "        dataset[idx] = new_signal\n",
    "        sig_mfcc =librosa.feature.mfcc(y=new_signal,sr=target_rate,n_fft=n_fft,hop_length=hop_length,win_length=win_length,n_mfcc=n_mfcc)\n",
    "        dataset_mfcc[idx] = sig_mfcc\n",
    "        idx += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
